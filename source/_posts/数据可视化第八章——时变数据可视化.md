title: 数据可视化第八章——时变数据可视化
tags: []
categories:
  - 数据可视化
date: 2019-08-24 11:22:00
author:
---
### 数据可视化第八章——时变数据可视化
时间是一个非常重要的维度和属性。随时间变化、带有时间属性的数据称为时变型数据（time-varying data 或者 temporal data）。处理时变型数据的方法有时候又与顺序型数据（sequential data）有相通之处。从宏观上看，数据类型包括数值型、有序型和类别型三类。其中，任意两个有序型数据之间都具有某种顺序关系，而数值型数据可看成某种有具体数值的有序型数据。在科学、工程、社会和经济领域，每时每刻都在产生大量的有序数据。据统计,1974-1980 年世界上的 15 种报纸和杂志上刊登的 4000 个图像集合的 75% 以时间序列排序。从语义上看,有序型数据可分为两类。<!--more--> 
+ 以时间轴排列的时间序列数据（time-series data；time-varying data），如：个人摄像机采集的视频序列、各种传感器设备获取的监测数据和股市股票交易数据、太阳随时间的变化、奥运会比赛日程、每日高血压药物服用时间、股票价格变动等。在时间序列数据中，每个数据实例都可以看做某个事件,事件的时间可当成一个变量。
+ 不以时间为变量，但具有内在的排列顺序的顺序型数据集，如文本、生物 DNA 测序和化学质谱等。这类数据的变化顺序可以映射为时间轴进行处理。

两类数据统称为时变型数据。它们在实际应用中量大、维数多、变量多,而且类型丰富，分布范围广泛。特别是在各类传感器网络、移动互联网应用中，以流模式（streaming）生成的流数据（streaming data）是一类特殊的具有无限长度时间轴的时变型数据。  
人类社会的微观活动和历史事件也构成了一个随时间变化的数据。历史学界的一个新理论——历史动力学（CliodynamIcs）通过考察人口数量、社会结构、国家强盛程度和政局的不稳定性等变量，认为人类历史有经验性规律和周期性。例如，人口下降时期每 10 年发生的不稳定事件数，是人口上升时期每 10 年发生的不稳定事件数的好几倍。在长期的社会趋势中，两种循环影响着政局的不稳定性：长达 200 至 300 年的世俗循环，如农业社会每过两三个世纪就遭逢一次一百年左右的不稳定期；50 年左右的父子两代循环。图 8.1 展示了每隔 50 年 （1870，1920，1970）美国城市暴力的周期图例。  
分析和理解时变型数据通常可以通过统计、数值计算和数据分析的方法完成。例如，考察时变序列数据的极值，计算两个时变序列数据的相似性，检测时变序列数据与某个数据分布的匹配性，快速检索时变序列数据，某个数据元素的变化情况。$k$ 个$(k>2)$ 数据元素在时变序列数据中出现的频率和概率，序列中相似子片段的检测等。这些任务同时也是流数据分析、序列分析的核心目标。  
从特征计算的角度看，也可采用传统的数据挖掘方法对时变型数据进行信号分解、模式挖掘和特征预测等处理，例如常用的粒子滤波器、卡尔曼滤波和隐马尔科夫链。  
在数据尺度中等时，上述方法可以取得令人满意的结果。然而，针对大尺度的时变型数据，自动的数据挖掘方法往往难以预测蕴藏其中的千变万化的规律。数据挖掘的结果通常带有噪声，需要人工解释和滤波。此时，采用合适的数据可视化方法展现原始数据或分析后的结果，可有效地揭示数据中隐藏的特征模式，展示与时间相关的变化规律和趋势。  
时变型数据的可视化方法可分为两类。一类方法采用静态方式展示数据中记录的内容，不随时间变化，但可采用多视角、数据比较等方法体现数据随时间变化的趋势和规律。另一类方法采用动画手法。可视化领域的主流观点认为，由于人类认知对动画的局限性，需谨慎看待采用动画方式可视化时变型数据的可行性和表达力。关于动画与可视化的关系，详见第 2 章相关章节。  
#### 8.1 时间属性的可视化
如果将时间属性或顺序性当成时间轴变量，那么每个数据实例是轴上某个变量值对的单个事件。对时间属性的刻画有三种方式。
+ **线性时间和周期时间：** 线性时间假定一个出发点并定义从过去到将来数据元素的线性时域。许多自然界的过程具有循环规律，如季节的循环。为了表示这样的现象，可以采用循环的时间域。在一个严格的循环时间域中，不同点之间的顺序相对于一个周期是毫无意义的，例如，冬天在夏天之前来临，但冬天之后也有夏天。
+ **时间点和时间间隔：** 离散时间点将时间描述为可与离散的空间欧拉点相对等的抽象概念。单个时间点没有持续的概念。与此不同的是，间隔时间表示小规模的线性时间域，例如几天、几个月或几年。在这种情况下，数据元素被定义为一个持续段，由两个时间点分隔。时间点和时间间隔都被称为时间基元。
+ **顺序时间、分支时间和多角度时间：**顺序时间、分支时间和多角度时间：顺序时间域考虑那些按先后发生的事情。对于分支时间、多股时间分支展开，这有利于描述和比较有选择性的方案（如项目规划）。这种类型的时间支持做出只有一个选择发生的决策过程。多角度时间可以描述多于一个关于被观察事实的观点（例如，不同目击者的报告）。

##### 8.1.1 线性和周期时间可视化
不同类别的时变型数据需采用不同的可视方法来表达。标准的显示方法将时间数据作为二维的线图显示，*x* 轴表示时间，*y* 轴表示其他的变量。例如，图 8.2 左图显示了一维时间序列图，其横轴表达线性时间、时间点和时间间隔，纵轴表达时间域内的特征属性。这种方法善于表现数据元素在线性时间域中的变化，却难以表达时间的周期性。周期是 28 天，从 4 个比较明显的部分我们可以推断出所有 7 天的整数倍作为周期。图 8.2 两幅图中描述的数据都是某地区三年时间内流感病例的数量，从中可以看出线性和周期时间的不同的重要影响。图 8.3 展现了一个不同显示周期下的时变序列数据的可视化效果。此外，为了体现时变型数据的周期结构，可以采用环状表示某时间段内的时间结构，如图 8.4 所示。  
图 8.5 采用单个时间轴对应多个属性轴的方式表达顺序时间、点时间和多角度时间，其中每个轴表达数据集的某个分析角度，顺序的时间轴表示时间的进程，线段表示不同时间点对应的不同属性。从每个不同的属性轴可以看出这种属性数据的时序关系。  
图 8.6 采用堆叠的语义流方法表达多个变量随时间演化的过程。这种雄叠流图方法既总量，又能显示多个时间序列数据的对比，且每个时间流的分段标签易读，还可以区分不同的层次，具有美感，常用于时间流数据的可视化。尽管时间轴本质是线性的，但仍然可以采用美观的可视化手段表现时变序列数据。  
时变型数据中的其他属性可以采用不同的可视化通道表达。例如，图 8.7 中华盛顿邮局发布的可视化作品展现了过去的 30 年里，电子产品的价格变化趋势。其中，使用圆的大小和颜色来分别表示电子产品的价格和类别。  
##### 8.1.2 日历时间可视化
时间属性可以和人类日历对应，并分为年、月、周、日、小时等多个等级。因此，采用日历表达时间属性，和我们识别时间的习惯符合。图 8.8、图 8.9 分别展示了三种日历视图。  
将日期和时间看成两个独立的维度，可用第三个维度编码与时间相关的属性，如图 8.10 所示。以日历视图为基准，也可在另一个视图上展现时间序列的数据属性，日历视图和属性视图通过时间属性进行关联。从日历视图上可以观察以季度、月、周、日为单位的趋势。对多个时间单位的数据进行聚类合并，可以观察不同时间段的趋势异同。图 8.11 展示了 5 种聚类后的单日内 6 点到 18 点之间的雇员在岗数目走势图，以及它们和两类平走势图的对比。左边的日历图的日期颜色和右边的曲线颜色一一对应,观者可以直观地观察右边的聚类曲线对应的日期的分布。这种对偶视图的方法，允许用户进行添加、删除、查看、操纵聚类等操作，并交互地发现和分析时间序列数据中蕴涵的信息。

##### 8.1.3 分支和多角度时间可视化
类似于叙事型小说，时变型数据中蕴涵的信息存在分支结构，对同一个事件也可能存在多个角度的刻画。按照时间组织结构，这类可视化可分为线性、流状，树状，图状等类型。  

**线性多角度时间可视化**  
为了呈现一个完整的事件历程和社会行为（如个人健康记录、历史事件），可采用类似于甘特图（用条形图表进度的可视化标志方法)的方式，使用多个条形图线程表现事件的不同属性随时间变化的过程，线条的颜色和厚度都可以编码不同的变量。观察者既可以交互地点击某个线程获取详细的细节，也可以直观地得到按时间排列的事件的概括。图 8.12 展示了个人健康记录信息可视化系统 LifeLine。  
IBM 开发的在线数据共享和可视化平台 Historio 则采用了环形可视化来呈现故事中蕴藏的周期性特征，如图 8.13 所示。它将故事构造为带有时间周期和离散事件（用小点标）的环状时间主线（timelines），其中时间从内环到外环排序，每个离散事件配备解释和标注，如照片、视频、地理信息和文档。这种线性时间可视化方法允许普通用户在可交互的时间线上构造解释和标注，从而表达某个故事情节和事件发展。系统还支持用户交互地搜索关键词，比较多个时间主线，查看事件细节和分享感兴趣事件。  

**流状分支时间主线可视化**  
基于河流的可视隐喻可展现时序型事件随时间产生流动、合并、分又和消失的效果，这种效果类似于小说和电影中的叙事主线。例如，软件开发中协作关系的演变类似于电影中的人物关系。每个开发人员在开发过程中用一条线表示，当两个程序员同时开发同一个模块的时候，他们的线条合并。可视化学者 Michael Owaga 开发的 Storylines 软件可读入软件版本件控制系统（如 SVN 等）的日志，从中读取开发者的信息和协作关系，自动绘制类似于电影人物关系图的软件开发历程图。图 8.14 展示了 Python 的开发历史。    
另一个例子是复杂的人际关系的动态可视化。传统方法将人物关系用杜会网络图表示，再用动画回放图的变化。更符合人类感知和认知的方法是采用静态的流状分支时间线可视化方法，在二维平面上展现这个动态过程。图 8.15 是艺术家手工绘制的电影“指环王”人物关系的演变，$x$ 轴代表时间，每一个人物用一条线表示，当两个人物在一起时，两条线合并，分开时，两条线也分开。与故事情节相关的其他信息也利用不同的颜色和标注表达。例如，灰色区域表示战斗或者有事件发生；圆点表示人物的死亡。图 8.15 下图展示了局部可视化细节：在某个时间点，4个哈比人出现了分歧。Frodo 和 Sam 离开了 Merry 和 Pippin，Aragorn、Legolas和 Gimli 也和哈比人失散了。在导致分开的事件中，死去的人是 Boromir。   
Tanahashi 在中自动地根据事件脉络生成流状分支时间主线可视化的算法，其核心是基于多目标函数优化的演化规律自动计算，如图 8.16 所示。  
##### 8.1.4 时间属性的动态可视化
尽管基于动画形式的可视化有着一定的局限性，也不是时变型数据可视化的主流，但在诠释某些动态事物的过程时,适当地采用动态可视化方法，有助于普通用户以可视的形式了解整个事件过程，达到一图胜千言的效果。例如，GapMinder 软件用动态可视化展示各国人口、经济的发展历程。2009 年 1 月 15 日，美国组约一架航班因故障，迫降哈德逊河。纽约时报的可视化工作室制作了一个动画，生动地阐述了从飞机起飞到飞机降落的全过程。图 8.17 是其中的一帧截图。
#### 8.2 多变量时变型数据可视化
多变量时变型数据是实际应用中常见的数据集。由于存在多个变量，可视化需要兼顾数据本身属性和数据集的顺序性，结合数据分析的方法展现和挖掘顺序型数据的规律。面向大尺度数据，首要任务是对数据进行抽象和重构，以便刻画复杂有序数据集的内蕴特征，生成紧凑的概述图像，方便索引和搜索，进而允许用户在交互分析过程中添加其他细节。这个流程与可视化的基本流程—“全局摘要；显示重要部分——缩放和过滤；按要求显示细节，进一步分析”相吻合，归纳为三类基本方法，即数据抽象、数据聚类和特征分析。  
+ 数据抽象指通过数据降维、特征选取和数据简化等方法，构建增强关键特征而抑制不相关细节的表达，获得有序数据流的时间相关或无关的内蕴量或隐含的特征模式。其挑战之一在于如何在线分析源源不断产生的数据流，方便用户及时做出决策。另一方面，实测数据通常包含谬误或自相矛盾的信息，即存在不确定性。因此，数据抽象包括排序、信息过滤、去噪、异常处理等操作。  
+ 聚类指将数据集划分为多个具有某种相似性的子集的操作。聚类过程实际上完成了对数据的抽象，因而允许对聚类后的集合进行分析和可视化，并在聚类基础上直接处理大尺度数据集。聚类操作的核心是定义恰当的距离或相似性度量，而这与具体应用和数据集相关。在聚类过程中，用户通常需要调整参数并验证结果，以达到最优的效果。
+ 特征分析包括特征抽取、语义分析等操作。在一个高维时变型数据中，通常假设其中蕴涵某些事件的演化规律。基于事件的可视化技术通常包含事件定义、事件抽取、基于事件的语义分析等三个步骤。

##### 8.2.1 基于线表示的可视化
高维抽象的时变非空间数据通常蕴涵宏观的、结构性的、随时间变化的规律。将时变序列中的每个数据采样点连接，原时变序列组成一条在高维空间的线，在低维空间可视化这条线可揭示高维空间的时间序列演化趋势。在[Ward2011]中介绍了三个基本步骤。
+ 第一步：高维曲线采样,采样的频率由用户交互指定。
+ 第二步：将采样后的高维曲线分段，便于刻画每段曲线的特性，小段之间可以重叠。分段尺寸、重叠程度也由用户交互指定。
+ 第三步：用主元分析法将高维曲线投影到二维空间，显示和研究曲线特性。
图 8.18 展示了采用高维连线投影法的心电图的二维可视化结果。在图 8.18（a）中每个粗点代表一条心电记录。图 8.18（b）是连线、降维后的结果，清晰地呈现了不同颜色标记圆弧，其中一个圈的某一部分和其他圈不一样（图中黑色部分），对应了心电图中的异常区间。  
采用静态方法可视化运动场景可用于精简、抽象、描述等目的。采用动作捕捉（Motion Capture）设备获取的人体动画序列是高维的时变序列。图 8.20 展现了一个基于高维空间投影法的可视化结果。

这个思路还可以用于比较不同人群的运动序列，合成新的运动序列。整可视化过程见图 8.21。此方法采用自组织映射（SOM）方法从运动数据库中提取一组能代表整个数据库的关键帧，形成对源数据库的本征刻画；然后，将关键帧通过多维尺度分析方法降维到二维平面，形成平面上的一组关键参考点；接着，对于任意一个运动列，对每一帧计算其与关键帧的相似性，并根据相似性计算该帧在二维平面上相对于参考点的位置；最后，按顺序连接所有帧在二维平面的位置。得到一个轨迹。这种方法直接将以时间为序的运动序列在一个可见空间中直观表现，且能清晰地显示不同运动序列之间的差异，可用于比较不同运动种类、不同个体运动和不同运动序列之间的动作差异。  

##### 8.2.2 基于图结构的可视化
基于事件的时变型或顺序型数据可视化的核心是事件演化的组织。用户根据领域需求和任务描述关注点，并基于此数据中找到与用户关注点实际匹配的事件，对事件分类获得不同类型；继而，根据事件类型的特征描述，从输入有序数据中检测事件，得到事件实例；最后，通过可视化方法将检测到的事件整合到可视表达中。  在可视化中，可采用树、图等非线性结构表述事件结构的非线性。图 8.22 上图展示了基于图结构的三维时变模拟飓风体数据集的表示。算法将数据中有语义的特定事件抽象为一个层次细节事件图。以数据的特征作为节点，事件关系作为链接对事件图的交互浏览或自动播放（以合适的起点和路径）形成解释性动画。事件图中的节点是从不同方面描述的不同层次细节（以时间区间划分）的事件特征，如暴风眼附近的速度、路径和风的旋转。叶节点是一个简单的基本事件，如匀速度。节点的子节点数目与该节点对应的时间区间中的事件复杂度有关。父子节点之间用树指针链接，不同事件在时间上的相似性用另外一种关系指针表示。每个节点的属性包括：事件特征、时间范围、事件特征的重要性。图 8.22 下图演示了基于该遍历结构的过程部分帧。在不同节点的跳转过程中，算法自动完成视点的光滑旋转和绘制参数的自动设置，获得平滑的淡入淡出效果。

##### 8.2.3 时间序列数据的可视化交互
直接可视化大规模的时变型数据难以呈现其全部细节，因此需要设计合适的交互方法表现重要的区域。代表性方法有概览加上下文、层次细节等（详见第 13 章）。  
常用的一种交互手段是从时变型数据中查询特定的时间序列,以便交互地发现特征和趋势。TimeSearcher 是一个基于时间盒子（timebox）表示的可视界面，允许用户实现直接指定时变趋势模式、操纵时变型数据集、基于实例查询给定的时变趋势模式。在图 8.23（a）中，黑色折线段是原始输入时变数据，用户选择的实例用蓝色长方框表示，淡灰色表示所有时变数据的范围；在图 8.23（b）中，右边蓝色框是系统自动计算的与左边样例类似的时变数据区段。  
在 TimeSearcher 的后续版本中，用户可以定制一个粗略的时间线形状，系统自动回整个数据集中形状相近的时间线段，见图 8.23（c）
#### 8.3 流数据可视化
流数据是一类特殊的时变型数据，输入数据（全部或部分）并不存储在可随机访问的磁盘或内存中，而是以一个或多个“连续数据流”的形式到达。常见的流数据有移动通信日志、网络数据（日志、传输数据包、警报等）、高性能集群平台日志、传感器网络记录、金融数据（如股票市场）、社交数据等。  
处理流数据与传统的数据池处理方法相比,有以下特点。
+ 数据流的潜在大小也许是无限的。
+ 数据元素在线到达,需要实时处理，否则数据的价值随时间的流逝可能降低。
+ 无法控制数据元素的到达顺序和数量，每次流入的数据顺序可能不一致。数量时多时少。
+ 某个元素被处理后，要么被丢弃，要么被归档存储。
+ 对于流数据的查询异常情况和相似类型比较耗时，人工检测日志相当乏味且易出错。

实时数据流计算在科研领域已有多年的研究。近年来，流数据在移动互联网领域被广泛产生，研究和使用流数据的可视化和分析成为研究热点。
##### 8.3.1 流数据可视化模型
流数据处理并没有一个固定的模型，通常按处理目的和方法的不同（如聚类、检索监控等）会有不同的模型。在这里我们参照[Rajaraman2012]中的流数据处理过程（见图 8.24），把不同的处理方法放在流数据处理器这样一个黑匣子里，综合可视化的过程得到了一个流数据模型。数据流进入流处理器后经过整理大部分原始数据会保存在归档数据库中，而另一部分关键数据保存在另一个便于存取的数据库中作为可视化的数据来源。关键数据进入可视化处理器后，经过一系列可视映射和布局等可视化过程转化为可视化输出呈现给用户。用户交互包括三个部分：一是输出内容的可视检索，二是对可视布局的基本交互，三是自定义的数据定制。其中，多数据库的设计既保护了原始数据，也提高了数据存取效率，而多处理器的设计也是为了同样的两个目的。值得注意的是，用户对数据的定只对定制时间之后的流数据有效，这也是流数据的特性,只在数据到达的时刻被处理。  
图 8.25 中的流数据分析流水线参考自[Urbanek2003]，表达了流数据的数据处理的流水线。到达的流数据按时间、空间进行分割或按规则聚合后进行摘要统计，形成一个统计模型或分析模型。可视化可以在流水线的任意过程中参与数据分析，但在一般应用中可视化往往在最后一步的统计和分析中参与分析，而用户交互通过数据定制会涉及前面的关键步骤，因此，图 8.24 和图 8.25 的两个流水线实际上是统一的。
##### 8.3.2 流数据处理技术
根据 Aggarwal 在[Charu2007]的第 1 章中的介绍，流数据挖掘的算法种类繁多，包括分类、聚类、频繁模式挖掘、降维等传统数据挖掘算法在流数据中的改进算法，大数据相关的统计方法、采样算法和哈希算法,以及滑动窗口、数据预测等流数据特有的算法。这节只关注窗口技术、时序数据相似性技术和符号技术,窗口技术是时序数据特有的技术，而相似性计算是时序数据聚类、分类、检索、降维以及异常检测的基础，符号技术将时序数据转化到另一个维度。窗口技术包括滑动窗口、衰减窗口和时间盒，给予不同时间段的数据不同的权重，让最近的数据发挥更大效用。时序数据相似性技术分为 4 类：基于形状的（shape-based）相似度、基于特征（feature-based）的相似度、基于模型的（model-based）相似度和基于压缩（compression - based）的相似度。本节以动态时间扭曲为例介绍时序数据相似性技术，而符号技术则以符号累积近似为代表。  
###### 8.3.2.1 窗口技术
在传统数据挖掘或一些流数据挖掘中，数据的重要性是相同的，数据处理技术在整个数据集汇总进行。但是，有时人们更关心最近的数据，以前的数据只有参考价值或者基本可以忽略。因此就需要一种技术在数据的时间上进行限定，这就是窗口技术。本节介绍滑动窗口、衰减窗口、时间盒（sliding window，decaying window，timebox）三种窗口技术。滑动窗口，顾名思义，指在时间轴上滑动的窗口，挖掘技术的对象限定为窗口内的数据；衰减窗口将历史数据考虑在内，每个数据项都被赋予一个随时间不断减小的减因子，从而达到越历史的数据权重越低的效果；时间盒是一种交互技术，通过时间盒框选部分数据进行联合搜索。  
滑动窗口的设计假设数据带有时效性，用户只关心最近一周、最近一天、最近一个小时等的数据，随着时间流逝，窗口向前滑动，始终只包含有效时间范围内的数据。滑动窗口数据与静态数据的区别是滑动窗口每向前推进一个时间单元（比如一分钟），只需要增加最近一分钟的数据，,删除最老的一分钟的数据。衰减窗口在衰减模型下考虑数据流的分类、聚类、降维等计算。一般衰减模型在每个数据上乘以一个衰减系数。历史数据的权重呈指数减小，显然新产生的数据相对于历史数据更能影响算法结果。  
如果按静态数据算法对滑动窗口进行分类、聚类、降维等计算,则需要在每次更新数据的时候重新获取数据、存储并执行算法，如此巨大的处理代价和存储开销，显然难以满足数据流实时在线处理的需要。即使数据更新只对受影响的数据进行操作，但由于要保存窗口内的所有数据，对于窗口内数据大小超过可用内存空间的情况，数据仍然需要磁盘存取。由于数据流处理有严格的时间与空间限制，确定且精确的数据流算法比较少见。对于大多数算法，只能以降低计算结果的精度为代价，从而达到降低算法时空复杂度的目的，实现流数据的实时处理。
###### 8.3.2.2 时序数据相似性计算
对于时序数据，不管是出于分类、聚类、降维还是有效检索，相似性计算都是非常重要的。动态时间扭曲（Dynamic Time Warpin，DTW）是基于形状的相似性算法。  
对于两个时序数据如序列 A：1,1,1,10,2,3 和序列 B：1,1,1,2,10,3，要测量序列的距离，也就是计算两个序列的相似性，通常采用欧式距离。然而这两个看起来很相似的序列的欧式距离却非常大。为了解决这个问题，人们提出了动态时间扭曲的方法，采用扭曲的序列对齐方式计算两个序列的距离。这一方法在机器学习，尤其是语音识别和签名识别上得到广泛应用。  
为了达到扭曲的目的，算法容忍序列的偏差，也就是说，序列的距离并不由相同位置的序列值计算得到，而是由序列的最短距离决定。DTW 的实现思想基于动态规划，计算两个序列的最短距离，也就是计算以两个序列为矩阵从$(1,1)$点到$(m,m)$点的最佳路径，$m$ 和 $n$ 分别为两个序列的长度。算法满足如下三个条件。
+ （1）距满足边界条件，路径要从矩阵的起始位置$(1,1)$开始计算到矩阵的结束位置$(m,m)$。
+ （2）距离满足连续性和单调性，要求路径的计算是连续的，反映在矩阵中就是是最佳路径必须是不间断的一条线。
+ （3）距离满足单调性，要求路径的计算是单调的，反映在矩阵中就是最佳路径必须是向前向上的一条线。

总的来说，矩阵的最佳路径必须是从起始位置$(1,1)$到结束位置$(m,m)$向前向上的一条线。算法步骤如下。
+ 定义最佳路径函数：定义 $ \pmb D(i,j)$ 为 $ A(1:i)$和$ B(1:j)$之间的动态时间扭转距离，对应从 $(1,1)$ 走到 $(i,j)$ 的距离。
+ 最佳路径的迭代关系：$\pmb D(i,j)=|A(i)-B(j)|+min \lbrace \pmb D(i-1,j),\pmb D(i-1,j-1),\pmb D(i,j-1) \rbrace$，起始条件为 $ \pmb D(1,1)=|A(1)-B(1)|$。
+ 最后的最佳路径则为  $ \pmb D(m,n)$。


以上述两个 A、B 序列为例，序列的欧式距离为 $Dist=|2-10|+|10-2|=16$。作矩阵如图 8.26 所示，最佳路径距离为 2，远小于欧式距离。
###### 8.3.2.3 符号技术
符号累积近似（Symbolic Aggregate Approximation，SAX）是一种针对时序数据的符号表达。数据经 SAX 表达转换后可以再用时序数据相似性算法快速得到其相似性。2003 年由加州大学河滨分校的 Eamonn Keogh和 Jessica Lin 首次提出了 SAX 方法，2008年 Eamonn Keogh 又提出了 iSA2X，增强了 SAX 的数据可扩展性，使之可以处理 TB 级别时序数据的索引和挖掘。简单来说，SAX 经过两次离散化将时序数据近似转化为字符串，所有时序数据的聚类、检索等操作都转化为字符串操作，并借助后缀树的数据结构和相关算法加速字符串操作。  
SAX 首先将时序数据经过逐段累积近似变换离散化，PAA 变换取该段内数值的平均值作为该段的离散值，然后将离散后的值分区间，每个区间内的值按顺序用字母表示。如图 8.27 所示，曲线是原始时序数据，第一次离散化把曲线转化为方波，第二次离散化把方波按值分布分为三段，分别用 a、b、c 表示，最后得到字符串“baabccbc”。再将字符串构造为一棵后缀树,可以将最小公共字串、字符串匹配等算法应用到 SAX 中，大大提高了时序数据计算的时间和空间复杂性。



##### 8.3.3 流数据可视化案例
流数据可视化按功能可以分为两种可视化类型：一种是监控型，用滑动窗四定个时间区间，把流数据转化为静态数据，数据更新方式可以是刷新，属于局部分断；另一种是叠加型，或者是历史型，把新产生的数据可视映射到原来的历史数据可视化结果上，更新方式是渐进式更新，属于全局分析。局部分析与全局分析各有侧重点，为了得到更加全面的分析结果，人们往往将两种可视化结合到一个系统中。为了不造成混乱，本节按数据类型介绍流数据可视化的案例，分别是系统日志监控流数据、文本流数据。不同的流数据虽然在某些情况下略有交集，但是由于可视化目标不同，可视化方法有明显差异。
###### 8.3.3.1 系统日志监控流数据
系统日志数据反映了一台机器、一个计算集群的系统性能，是商业智能中最重要的数，在工业界已经有 Splunk、Loggly、Flume 等诸多或收费或开源的系统日志监控工具。这些工具在系统底层插入脚本获取性能数据，再用基本的条形图、折线图等基本统计图和信息检索工具得到系统性能的概要分析。本节介绍三个可视化表达更加丰富的系统日志监控方法。  
LogTool 是一个可视化用户浏览行为的工具，它通过分析数据包的不同 IP 地址和端口，判断用户正在使用的网络程序或者服务。整个可视化基于一天的时间长度，在图中类似时钟的时间圆被均分为 5 分钟一格，一共 288 格，呈向圆外放射式的柱状图，如图 8.28所示。灰色柱代表网络上行流量，紫色柱代表用户收到的下行流量，大圆内部的点画线代表用户发出的 HTTP 连接请求数目。基于这三个数据，可以判断网络流量是不是由用户浏览网页引起的。例如，17:00—18:00 这段时间的网络流量上升是由于有大量网页浏览，而 20:00—23:00 这段时间网络流量很大，却并不都是由网页浏览引起的。图中蓝色的泡泡则显示使用 Google 服务，比如 Google Maps、 YouTube 等这些需要和 Google 服务器连接的服务。时间圆中的一些空白则是用户关掉他们的手提电脑的时间。  
LiveRAC 是一个交互式系统管理可视化工具，支持对大量的系统性能管理时间序列数据的分析。 LiveRAC 使用可重排序的矩阵表达设备及其性能之间的关系，每
个关系用折线图表示，整个矩阵是一个高信息密度的监控界面，可以按用户的兴趣自由地进行语义缩放。不管是缩略图还是展开图，矩阵的每个区块都用颜色表达该区块所对应设备的对应性能的均值，通过重排序可以看出设备间的性能分布关系。LiveRAC 表达多层次的信息细节，允许任意分组，以及设备和性能的可视比较。图 8.29 展示了一天的系统性能管理时序数据, LiveRAC 系统对超过 4000 台设备 11 个性能进行监控，每一行是一台设备，每列是一个性能属性，包括 CPU、内存等，图中行按 CPU 性能的最大值对设备进行排序。其中前三台设备展开可以看到详细的性能时间分布折线图,前 13 行放大到足以显示设备文本标签，前几十行可以看到简略的性能值浮动及最大值，其他行缩略显示。每个折线图中的时同标线标记图中的异常值，时间标线的纵向比较同样可以反映异常在不同设备中的时延，从而表达不同设备的依赖关系。  
IOVIS 是针对高性能计算集群 I/O 系统的可视分析工具，其目标是为高性能计算集群的 I/O 系统提供点对点的分析。IOⅥS 包括一个连接集群 I/O 系统软件的数据收集工具并对 I/O 进行追踪。根据追踪结果 IOVIS 可视分析工具为用户提供可扩展的可视化和交互技术，提取集群 I/O 行为分析。因此，用户可以对不同 I/O 软件层的应用 I/O 请求执行深入地分析，探索什么时候、什么位置、为什么会产生 I/O 瓶颈。图 8.30为美国阿贡国家实验室的 Jazz 集群的共享文件上进行的 IOR 基准测试结果。整个过程是一个相当一致的层次性分析过程，由上到下依次为系统 I/O 的时间线、基于 I/O 事件点的 I/O 操作时间图，以及 I/O 二部矩阵图和 I/O 甘特图。从图中可以看出，整个集群系统 I/O 经过一段时间升到峰值然后下降，呈现出集群服务器顺序工作导致负载不均衡的趋势。图的左边表现了在执行初期只有一半服务器在执行写操作，这部分服务器的忙碌程度持续升高，而另一半服务器则处于空闲状态。图的中间部分表现在执行中期相同的模式转移到另一半服务器，前一半服务器已经完成写操作，开始读操作。图的右边表现在执行后期另一半服务器即将结束读操作，前一半服务器已经完成所有操作处于空闲状态。
###### 8.3.3.2 文本流数据
上节提到的系统日志数据也有一部分为文本数据，如系统错误描述等，本节主要从事件角度对文本进行可视分析，挖掘事件的发生、发展及变化。本节以新闻事件为例介绍两种文本流数据的可视化方法。  
EventRiver 是一个广播新闻视频集合的交互式探索工具。EventRiver 首先使用增量式聚类算法从一系列事件中提取热门话题，然后用河流的隐喻将事件的语义和上下文在一个布局界面中自然地表达出来。用户在 EventRiver 可视化结果上可以进行丰富的交互操作，检索并浏览自己感兴趣的话题事件，对话题事件作进一步的可视分析等。图 8.31 用 EventRiver 可视化工具对从 2006 年 8月 1 日到 24 日的 29211 个新闻报告进行了可视化。$X$ 轴是时间轴，一个事件用一段流表示，事件的重要性用流在 $Y$ 轴上的宽度编码。在过滤了不重要的新闻事件后，相同颜色的事件在时间上连续，形成了一个持续进行的话题。话题中有代表性的事件用两个文本标签标识，黄色背景的文本表达事件的内容关键词，而白色背景的文本表达时间的上下文信息。从图中可以看出，表示巴以关系的红色新闻事件是 2006年8 月上旬的热门新闻话题，而到了 8 月下旬话题转变为美国 6 岁的选美皇后
 Jonbenet Ramsey 谋杀案的嫌疑犯 John Mark Karr 在泰国曼谷被拘捕的新闻。  
StreamIT 是另一个在线新闻流的可视化工具，该工具结合动态力引导布局、自动话题建模技术展现了新闻的发展和演变。用户可以对新闻事件进行动态聚类、细节探索以及新闻动态演变探索等交互操作，并按用户感兴趣的关键词和话题对事件进行检索，从而观察热门事件的爆发和演变。 StreamIT 系统如图 8.32 所示，左边是动态可视化窗口，动态可视化窗口下面包括播放/停止按键，可以动态展示 2010  年 2 月到 8 月间的新闻演化；右上角是关键词窗口，用户可以通过自定义关键词的权重对新闻进行重聚类和重布局，也可以通过为关键词分配颜色对感兴趣的关键词所对应的事件进行追踪；右下角是原始新闻列表。图中将 2010 年 2 月到 8 月的新闻事件进行了可视化，聚为若干类，用户将政治相关新闻标为绿色，国际关系标为红色。
##### 8.3.4 并行流计算框架
流计算强调的是数据流的形式和实时性。流式计算系统在启动时，一般数据并没有完全到位，而是经由外部数据流源源不断地流入，并且不像批处理系统重视的是总数据处理的吞吐，而是对数据处理的低延迟，希望进入的数据越快处理越好。这里的思想是数据的价值随着时间的递增而递减，所以数据越快被处理，结果就越有价值，这也是实时处理的价值所在。为了解决海量数据流计算的问题，Yahoo!、 Twitter、 Facebook 等 IT 公司纷纷推出他们的并行流计算框架/平台，典型的有  Yahoo! 的分布式流计算平台 S4、Twitter 的实时数据处理框架 Storm、Facebook  的实时数据处理分析平台 PUMA 以及斯坦福的流数据管理系统 STREAM。下文介绍在开源平台上应用广泛的 S4 和 Storm。

**S4 （Simple Scalable Streaming System，简单可扩展的流系统)**  
S4 最初是 Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。但是 S4 对流数据的高可用性和良好的用户体验使其成为现在最流行的流数据计算框架。S4 最大的优点是低延迟、可扩展；最大的缺点是部分容错，不支持节点的动态增减。

**Twitter 实时数据处理框架 Storm**  
Storm 核心的抽象概念是“流”。流是一个分布式并行创建和处理的无界的连续元组（tuple）。流通过一种模式来定义，该模式是给流元组中的字段命名。实时应用的逻辑被打包在 Storm 拓扑里。Storm 拓扑类似于 MapReduce 任务，一个关键的区别是 MapReduce 任务运行一段时间后最终会完成，而 Storm 拓扑一直运行直到被用户关闭。一个拓扑是由喷嘴（spouts）和螺栓（bolts）组成的图。spout  是拓扑中流的源泉，通常 spouts 从外部资源读取元组，然后发射元组到拓扑中。拓扑中的所有处理都在 bolts 中完成，如过滤、业务功能、聚合、连接（合并）、访问数据库等。spouts 和 bolts 之间通过流分组连接起，指定每个 bolt  应接收的输入流是定义 bolts 的一部分工作，流分组定义流应该如何分割到各个任务。Storm 包括 6 种流分组类型。
+ （1）随机分组（Shuffle grouping）：随机分发元组到 bolt 的任务，保证每个任务获得相等数量的元组。
+ （2）字段分组（Fields grouping）：根据指定字段分割数据流并分组。例如，根据“usei-id”字段，相同“user-id”的元组总是分发到同一个任务，不同“ user-id”的元组可能分发到不同的任务。
+ （3）全部分组（All grouping）：元组被复制到 bolt 的所有任务。小心使用该分组。
+ （4）全局分组（Global grouping）：全部流都分配到 bolt 的同一个任务，明确地说是分配给 ID 最小的那个任务。
+ （5）无分组（None grouping）：你不需要关心流是如何分组的。目前，无分组等效于随机分组。但最终 storm 将把无分组的 bolts 放到 bolts 或 spouts 订阅它们的同一线程去执行（如果可能）。
+ （6）直接分组（Direct grouping）：这是一个特别的分组类型。元组生产者决定元组由哪个元组消费者任务接收。

Storm 的优点是适用场景广泛，可以用来处理消息和更新数据库（消息流处理），对一个数据量进行持续的查询并返回客户端（持续计算），或者对一个耗资源的查询进行实时计算任务，所需要做的就是增加机器并且提高这个计算任务的并行度设置。作为 Storm 可伸缩性的一个例证，一个 Storm 应用在一个有 10 个节点的集群上每秒处理 1000000个消息——包括每秒一百多次的数据库调用。Storm 也使用 ZooKeeper 来协调集群内的各种配置，使得 Storm 的集群可以很容易地扩展很大。与S4 相比，Storm 更加可靠，保证所有的数据被成功地处理。容易管理是 Storm 的设计目标之一。与 Hadoop 相比，Storm集群更易于管理。Storm 也拥有非常好的容错性，如果在消息处理过程中出了一些异常，它会重新安排这个出问题的处理逻辑。Storm 保证一个处理逻辑永远运行，除非用户要求停止该逻辑。Storm 的拓扑和消息处理组件可以用任何语言来定义，语言的无关性使得 Storm 能被更多用户接受。